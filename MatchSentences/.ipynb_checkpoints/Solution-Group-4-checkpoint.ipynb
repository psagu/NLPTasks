{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 4\n",
    "# Pol Sagu Gasol\n",
    "# Irene***   \n",
    "# Anne***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy\n",
    "import scipy.sparse\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "file = open('test.csv', encoding= \"utf8\")\n",
    "data = file.readlines()[1:]\n",
    "df = file.read() \n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0,What are the hottest IT startup companies in Mumbai?\\n', '1,How often do you drink coffee (-based) drinks?\\n', '2,Which contries provide financial help to India?\\n', '3,What are some interesting facts about the NSG?\\n', '4,Why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour?\\n']\n",
      "\n",
      "[['0', 'What are the hottest IT startup companies in Mumbai?\\n'], ['1', 'How often do you drink coffee (-based) drinks?\\n'], ['2', 'Which contries provide financial help to India?\\n'], ['3', 'What are some interesting facts about the NSG?\\n'], ['4', 'Why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour?\\n']]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:5])\n",
    "split_data = []\n",
    "for i in data:\n",
    "    split_data.append(i.split(\",\"))\n",
    "print()\n",
    "print(split_data[0:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_cleaning(text):\n",
    "    text = text.lower()\n",
    "    clean_string = \"\"\n",
    "    for a in text:\n",
    "        if (a >= 'a' and a <= 'z'):\n",
    "            clean_string += str(a)\n",
    "        elif ord(a) >= 48 and ord(a) <= 57:\n",
    "            clean_string += str(a)\n",
    "        else:\n",
    "            clean_string += \" \"\n",
    "    return(clean_string)\n",
    "\n",
    "\n",
    "\n",
    "ID = []\n",
    "for i in range(len(data)):\n",
    "    ID.append(i)\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "question = []\n",
    "for i in split_data:\n",
    "    question.append(i[1:]) \n",
    "question2 = []\n",
    "for text in question:\n",
    "    question2.append(\",\".join(text))\n",
    "\n",
    "#----------------------------------------------------------\n",
    "\n",
    "cleanText = [] #application of the string_cleaning function\n",
    "for i in range(len(ID)):\n",
    "    a = string_cleaning(question2[i])\n",
    "    cleanText.append(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run only one of the next 4 cells (without lemmitization - lemmitization - Porter - Lancaster)\n",
    "## We included all methods and the accuracy we scored to show what methods we tried and what works best\n",
    "## For us, Porter worked best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## without lemmitization/stemming -> accuracy = 0.9159\n",
    "\n",
    "stopwords = ['a', 'and', 'the', 'is', 'in', 'on', 'at','what', 'why', 'how'] #these stopwords don't add any accuracy\n",
    "\n",
    "cleanText2 = []\n",
    "for text in cleanText:\n",
    "    sentence = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords:\n",
    "            sentence.append(word)\n",
    "    cleanText2.append(\" \".join(sentence))\n",
    "        \n",
    "print(cleanText[0:5])\n",
    "print()        \n",
    "print(cleanText2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization -> accuracy = 0.9382\n",
    "\n",
    "cleanText2 = []\n",
    "for text in cleanText:\n",
    "    sentence = []\n",
    "    for word in text.split():\n",
    "        sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    cleanText2.append(\" \".join(sentence))\n",
    "        \n",
    "print(cleanText[0:5])\n",
    "print()        \n",
    "print(cleanText2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what are the hottest it startup companies in mumbai  ', 'how often do you drink coffee   based  drinks  ', 'which contries provide financial help to india  ', 'what are some interesting facts about the nsg  ', 'why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour  ']\n",
      "\n",
      "['what are the hottest it startup compani in mumbai', 'how often do you drink coffe base drink', 'which contri provid financi help to india', 'what are some interest fact about the nsg', 'whi is it that even in fair skin women the crotch and inner thigh near crotch are dark in colour']\n"
     ]
    }
   ],
   "source": [
    "## PorterStemmer -> accuracy = 0.9533\n",
    "\n",
    "cleanText2 = []\n",
    "for text in cleanText:\n",
    "    sentence = []\n",
    "    for word in text.split():\n",
    "        sentence.append(porter.stem(word))\n",
    "    cleanText2.append(\" \".join(sentence))\n",
    "        \n",
    "print(cleanText[0:5])\n",
    "print()        \n",
    "print(cleanText2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LancasterStemmer -> accuracy = 0.9502\n",
    "\n",
    "cleanText2 = []\n",
    "for text in cleanText:\n",
    "    sentence = []\n",
    "    for word in text.split():\n",
    "        sentence.append(lancaster.stem(word))\n",
    "    cleanText2.append(\" \".join(sentence))\n",
    "        \n",
    "print(cleanText[0:5])\n",
    "print()        \n",
    "print(cleanText2[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform(cleanText2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 6225)\n",
      "\n",
      "  (0, 6066)\t0.11938801653110095\n",
      "  (0, 455)\t0.17054907322190935\n",
      "  (0, 5554)\t0.12662481213083943\n",
      "  (0, 2677)\t0.5620063151416798\n",
      "  (0, 2959)\t0.22849942959943018\n",
      "  (0, 5257)\t0.45060047890605415\n",
      "  (0, 1263)\t0.37791969871821207\n",
      "  (0, 2782)\t0.16856857831011446\n",
      "  (0, 3664)\t0.44528993772061604\n",
      "  (1, 2685)\t0.12200606543031893\n",
      "  (1, 3866)\t0.3688157367837451\n",
      "  (1, 1710)\t0.13469526146566352\n",
      "  (1, 6199)\t0.16771725910523938\n",
      "  (1, 1758)\t0.7282671956796551\n",
      "  (1, 1211)\t0.3739668360388556\n",
      "  (1, 646)\t0.36413359783982757\n",
      "  (2, 6078)\t0.24629736654230464\n",
      "  (2, 1340)\t0.5767766149544987\n",
      "  (2, 4398)\t0.4106734593442843\n",
      "  (2, 2168)\t0.4588486025675739\n",
      "  (2, 2579)\t0.36218382133070676\n",
      "  (2, 5620)\t0.15999177177875978\n",
      "  (2, 2804)\t0.26588931140103883\n",
      "  (3, 6066)\t0.12782485250480466\n",
      "  (3, 455)\t0.18260132601953913\n",
      "  :\t:\n",
      "  (9997, 455)\t0.20462352799757075\n",
      "  (9997, 6199)\t0.2490088930230957\n",
      "  (9997, 368)\t0.318480150687933\n",
      "  (9997, 2230)\t0.2490088930230957\n",
      "  (9997, 3299)\t0.476836659055345\n",
      "  (9997, 5572)\t0.6962740856530341\n",
      "  (9998, 6066)\t0.11513691105868334\n",
      "  (9998, 455)\t0.164476251848748\n",
      "  (9998, 2782)\t0.1625662773543472\n",
      "  (9998, 5620)\t0.16215330292757144\n",
      "  (9998, 1012)\t0.39756905417137545\n",
      "  (9998, 2719)\t0.4568460336807113\n",
      "  (9998, 2597)\t0.37989911128489096\n",
      "  (9998, 4373)\t0.4401433827975533\n",
      "  (9998, 563)\t0.44961159082750257\n",
      "  (9999, 6066)\t0.09766972153359225\n",
      "  (9999, 455)\t0.13952389003009186\n",
      "  (9999, 5554)\t0.10359004613198153\n",
      "  (9999, 2782)\t0.1379036739300672\n",
      "  (9999, 368)\t0.21715777240375694\n",
      "  (9999, 4454)\t0.30176319139276514\n",
      "  (9999, 947)\t0.2659625549816614\n",
      "  (9999, 2894)\t0.6849387197363983\n",
      "  (9999, 501)\t0.32320420912157755\n",
      "  (9999, 5499)\t0.3983575976808556\n"
     ]
    }
   ],
   "source": [
    "print (matrix.shape) #Now we have the TF-IDF matrix (tfidf_matrix) for each document (the number of rows of the matrix) \n",
    "print()\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identity diagonal\n",
      "[[1.         0.         0.         ... 0.0519996  0.06920081 0.07181956]\n",
      " [0.         1.         0.         ... 0.04176309 0.         0.        ]\n",
      " [0.         0.         1.         ... 0.         0.02594319 0.        ]\n",
      " ...\n",
      " [0.0519996  0.04176309 0.         ... 1.         0.05014802 0.11170061]\n",
      " [0.06920081 0.         0.02594319 ... 0.05014802 1.         0.05661224]\n",
      " [0.07181956 0.         0.         ... 0.11170061 0.05661224 1.        ]]\n",
      "\n",
      "Diagonal filled with zeros\n",
      "[[0.         0.         0.         ... 0.0519996  0.06920081 0.07181956]\n",
      " [0.         0.         0.         ... 0.04176309 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.02594319 0.        ]\n",
      " ...\n",
      " [0.0519996  0.04176309 0.         ... 0.         0.05014802 0.11170061]\n",
      " [0.06920081 0.         0.02594319 ... 0.05014802 0.         0.05661224]\n",
      " [0.07181956 0.         0.         ... 0.11170061 0.05661224 0.        ]]\n",
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "out = cosine_similarity(matrix, matrix)\n",
    "print(\"Identity diagonal\")\n",
    "print(out)\n",
    "numpy.fill_diagonal(out,0) #fill the diagonal with zeros in order to ignore the cosine similarity between each sentence and itself\n",
    "print()\n",
    "print(\"Diagonal filled with zeros\")\n",
    "print(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n",
      "float64\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "[0.66175085 0.87877727 0.75525146 ... 0.88475019 0.78197445 0.83064329]\n",
      "[8808 2103 1386 ... 8431 7722 1026]\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)\n",
    "print(out.dtype)\n",
    "print(type(out))\n",
    "print(type(out[1]))# it is an array of arrays\n",
    "print(out.max(axis=1)) # maximum per one dimension (each row) \n",
    "print(out.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8808, 2103, 1386, 35, 7409]\n"
     ]
    }
   ],
   "source": [
    "pred_id = list(out.argmax(axis=1)) #we get the maximum argument/index of each row, which is the sentence with highest similarity.\n",
    "print(pred_id[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0,What are the hottest IT startup companies in Mumbai?\\n', '1,How often do you drink coffee (-based) drinks?\\n', '2,Which contries provide financial help to India?\\n', '3,What are some interesting facts about the NSG?\\n', '4,Why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour?\\n']\n",
      "\n",
      "['0,What are the hottest IT startup companies in Mumbai?', '1,How often do you drink coffee (-based) drinks?', '2,Which contries provide financial help to India?', '3,What are some interesting facts about the NSG?', '4,Why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour?']\n",
      "\n",
      "['0,What are the hottest IT startup companies in Mumbai?,8808', '1,How often do you drink coffee (-based) drinks?,2103', '2,Which contries provide financial help to India?,1386', '3,What are some interesting facts about the NSG?,35', '4,Why is it that even in fair skinned women the crotch and inner thighs near crotch are dark in colour?,7409']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_data = copy.deepcopy(data)\n",
    "\n",
    "print(new_data[0:5])\n",
    "print()\n",
    "\n",
    "sentence = []\n",
    "for text in new_data:\n",
    "    clean = text.strip()\n",
    "    sentence.append(clean)\n",
    "    \n",
    "print(sentence[0:5])  \n",
    "print()\n",
    "\n",
    "sentences_id = []\n",
    "for i in range(len(sentence)):\n",
    "    sentences_id.append(sentence[i] + \",\" + str(pred_id[i]))\n",
    "\n",
    "print(sentences_id[0:5])\n",
    "print()\n",
    "    \n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "fp = open( \"result.csv\", \"w\" )    \n",
    "fp.write(\"ID,TEXT,PARA_ID\\n\")\n",
    "for line in sentences_id:\n",
    "    fp.write(line+\"\\n\")\n",
    "fp.close()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
